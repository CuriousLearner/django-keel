# AWS ECS Fargate Deployment

Deploy {{ project_name }} to AWS ECS using Fargate for serverless container deployment.

## Overview

This directory contains Terraform configuration for deploying to AWS ECS Fargate:

- **Serverless**: No EC2 instances to manage
- **Auto-scaling**: Scales based on CPU/memory
- **Load Balanced**: Application Load Balancer included
- **High Availability**: Multi-AZ deployment
- **Cost Effective**: Pay only for resources used

## Prerequisites

- AWS CLI installed and configured
- Terraform >= 1.0
- Docker for building images
- AWS ECR repository created
- RDS PostgreSQL database (or use Aurora Serverless)

## Quick Start

### 1. Build and Push Docker Image

```bash
# Login to ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com

# Build image
docker build -t {{ project_slug }} .

# Tag image
docker tag {{ project_slug }}:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/{{ project_slug }}:latest

# Push to ECR
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/{{ project_slug }}:latest
```

### 2. Configure Terraform

```bash
cd deploy/ecs/terraform

# Initialize Terraform
terraform init

# Create terraform.tfvars
cat > terraform.tfvars <<EOF
project_name     = "{{ project_slug }}"
environment      = "production"
aws_region       = "us-east-1"
container_image  = "<account-id>.dkr.ecr.us-east-1.amazonaws.com/{{ project_slug }}:latest"
database_url     = "postgresql://user:pass@rds-endpoint:5432/{{ project_slug }}"
secret_key       = "your-secret-key-here"
allowed_hosts    = "{{ project_slug }}.example.com"
EOF
```

### 3. Deploy

```bash
# Plan deployment
terraform plan

# Apply deployment
terraform apply

# Get ALB URL
terraform output alb_url
```

## Architecture

```
Internet
   |
   v
Application Load Balancer (ALB)
   |
   v
ECS Service (Fargate)
   |
   +-- Task 1 (Container)
   +-- Task 2 (Container)
   +-- Task N (Container)
   |
   v
RDS PostgreSQL / Aurora Serverless
   |
   v
S3 (Static/Media Files)
```

## Configuration

### Environment Variables

Set these in AWS Secrets Manager or Systems Manager Parameter Store:

```bash
DJANGO_SECRET_KEY=<your-secret-key>
DATABASE_URL=postgresql://...
ALLOWED_HOSTS={{ project_slug }}.example.com
DEBUG=False
{% if cache == 'redis' -%}
REDIS_URL=redis://...
{% endif -%}
{% if background_tasks in ['celery', 'both'] -%}
CELERY_BROKER_URL=redis://...
{% endif -%}
{% if use_sentry -%}
SENTRY_DSN=<your-sentry-dsn>
{% endif -%}
AWS_STORAGE_BUCKET_NAME={{ project_slug }}-media
AWS_ACCESS_KEY_ID=<from-iam>
AWS_SECRET_ACCESS_KEY=<from-iam>
```

### Task Definition

The ECS task definition includes:

- **CPU**: 256-1024 (0.25-1 vCPU)
- **Memory**: 512-2048 MB
- **Port Mappings**: 8000 (Gunicorn)
- **Health Check**: `/health/` endpoint
- **Logging**: CloudWatch Logs

### Auto Scaling

Auto-scaling configuration:

- **Min Tasks**: 2
- **Max Tasks**: 10
- **Target CPU**: 70%
- **Target Memory**: 80%
- **Scale-in Cooldown**: 300s
- **Scale-out Cooldown**: 60s

## Database Options

### RDS PostgreSQL

```hcl
# Deploy with RDS
terraform apply -var="use_aurora=false"
```

### Aurora Serverless v2

```hcl
# Deploy with Aurora Serverless
terraform apply -var="use_aurora=true"
```

Benefits of Aurora Serverless:
- Automatically scales based on load
- Pay per second
- Pause when inactive (dev/staging)

## Static & Media Files

Configure S3 for static and media files:

```python
# settings/prod.py
AWS_STORAGE_BUCKET_NAME = env("AWS_STORAGE_BUCKET_NAME")
AWS_S3_REGION_NAME = env("AWS_REGION", default="us-east-1")
AWS_S3_CUSTOM_DOMAIN = f"{AWS_STORAGE_BUCKET_NAME}.s3.amazonaws.com"

# Static files
STATICFILES_STORAGE = "storages.backends.s3boto3.S3StaticStorage"

# Media files
DEFAULT_FILE_STORAGE = "storages.backends.s3boto3.S3Boto3Storage"
```

## Migrations

### One-Time Migrations

Run migrations as a one-off task:

```bash
aws ecs run-task \
  --cluster {{ project_slug }}-cluster \
  --task-definition {{ project_slug }}-migrate \
  --launch-type FARGATE \
  --network-configuration "awsvpcConfiguration={subnets=[subnet-xxx],securityGroups=[sg-xxx],assignPublicIp=ENABLED}"
```

### Automated Migrations

Use ECS Exec or create a migration task that runs before deployment.

## Monitoring

### CloudWatch Metrics

Key metrics to monitor:

- CPU Utilization
- Memory Utilization
- Request Count
- Target Response Time
- Unhealthy Host Count

### CloudWatch Alarms

Set up alarms for:

- High CPU (> 80%)
- High Memory (> 85%)
- Failed Health Checks
- 5xx Error Rate

### Logs

View logs:

```bash
# Stream logs
aws logs tail /ecs/{{ project_slug }} --follow

# Filter for errors
aws logs filter-log-events \
  --log-group-name /ecs/{{ project_slug }} \
  --filter-pattern "ERROR"
```

## CI/CD Integration

### GitHub Actions

```yaml
name: Deploy to ECS

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: {% raw %}${{ secrets.AWS_ACCESS_KEY_ID }}{% endraw %}
          aws-secret-access-key: {% raw %}${{ secrets.AWS_SECRET_ACCESS_KEY }}{% endraw %}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and push image
        env:
          ECR_REGISTRY: {% raw %}${{ steps.login-ecr.outputs.registry }}{% endraw %}
          IMAGE_TAG: {% raw %}${{ github.sha }}{% endraw %}
        run: |
          docker build -t $ECR_REGISTRY/{{ project_slug }}:$IMAGE_TAG .
          docker push $ECR_REGISTRY/{{ project_slug }}:$IMAGE_TAG

      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster {{ project_slug }}-cluster \
            --service {{ project_slug }}-service \
            --force-new-deployment
```

## Cost Optimization

Tips for reducing costs:

1. **Right-size tasks**: Start with smaller CPU/memory
2. **Use Spot**: Consider Fargate Spot for non-critical workloads
3. **Aurora Serverless**: Auto-pause in dev/staging
4. **CloudWatch retention**: Set log retention to 7-30 days
5. **S3 lifecycle**: Move old media to Glacier
6. **Reserved capacity**: For predictable workloads

## Troubleshooting

### Task Won't Start

Check:
- ECR image exists and is accessible
- Security groups allow traffic
- Subnets have route to internet (for pulling images)
- IAM role has correct permissions

### Health Check Failing

- Ensure `/health/` endpoint is accessible
- Check security group rules
- Verify container is listening on port 8000
- Check CloudWatch logs for errors

### High Costs

- Review CloudWatch metrics for over-provisioning
- Consider Aurora Serverless pause
- Enable S3 lifecycle policies
- Use Fargate Spot for dev/staging

## Cleanup

To destroy all resources:

```bash
cd deploy/ecs/terraform
terraform destroy
```

## Resources

- [AWS ECS Best Practices](https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/)
- [Fargate Pricing](https://aws.amazon.com/fargate/pricing/)
- [Django on ECS Guide](https://testdriven.io/blog/deploying-django-to-ecs-with-terraform/)
