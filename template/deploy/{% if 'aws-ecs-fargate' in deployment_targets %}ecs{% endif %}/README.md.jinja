# AWS ECS Fargate Deployment

Deploy {{ project_name }} to AWS ECS using Fargate for serverless container deployment with complete Infrastructure as Code.

## Overview

This directory contains a complete implementation for deploying to AWS ECS Fargate:

### âœ… What's Included

- **Complete Terraform Configuration**: Full IaC setup with modular architecture
- **Automated Deployment Script**: One-command deployment with `deploy.sh`
- **CI/CD Pipeline**: GitHub Actions workflow for automated deployments
- **Networking**: VPC with public/private subnets, NAT gateways, and VPC endpoints
- **Database Options**: RDS PostgreSQL or Aurora Serverless v2
- **Storage**: S3 buckets for static/media files with CDN-ready configuration
- **Security**: Secrets Manager, IAM roles, security groups
- **Monitoring**: CloudWatch logs, metrics, and alarms
- **Auto-scaling**: Target tracking and scheduled scaling
- **Cost Optimization**: Fargate Spot support, right-sizing recommendations

### ðŸ“ Directory Structure

```
ecs/
â”œâ”€â”€ deploy.sh                    # Main deployment script
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf                  # Main Terraform configuration
â”‚   â”œâ”€â”€ variables.tf             # Input variables
â”‚   â”œâ”€â”€ outputs.tf               # Output values
â”‚   â”œâ”€â”€ network.tf               # VPC and networking
â”‚   â”œâ”€â”€ ecs.tf                   # ECS cluster and services
â”‚   â”œâ”€â”€ alb.tf                   # Application Load Balancer
â”‚   â”œâ”€â”€ database.tf              # RDS/Aurora configuration
â”‚   â”œâ”€â”€ storage.tf               # S3 and Redis
â”‚   â”œâ”€â”€ security.tf              # Security groups and secrets
â”‚   â”œâ”€â”€ ecr.tf                   # Container registry
â”‚   â””â”€â”€ terraform.tfvars.example # Example variables file
â””â”€â”€ .github-workflows-ecs.yml   # GitHub Actions CI/CD
```

## Prerequisites

- AWS CLI installed and configured
- Terraform >= 1.0
- Docker for building images
- jq for JSON processing
- Python {{ python_version }} with Django installed

## Quick Start

### Option 1: Automated Deployment (Recommended)

Use the deployment script for a fully automated setup:

```bash
# Make script executable
chmod +x deploy/ecs/deploy.sh

# Run full deployment
./deploy/ecs/deploy.sh

# Or with options
./deploy/ecs/deploy.sh --environment production --region us-west-2
```

The script will:
1. Check all dependencies
2. Create ECR repository
3. Build and push Docker image
4. Initialize Terraform
5. Deploy infrastructure
6. Run database migrations
7. Update ECS service
8. Show deployment information

### Option 2: Manual Deployment

#### 1. Build and Push Docker Image

```bash
# Login to ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com

# Build image
docker build -t {{ project_slug }} .

# Tag image
docker tag {{ project_slug }}:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/{{ project_slug }}:latest

# Push to ECR
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/{{ project_slug }}:latest
```

#### 2. Configure Terraform

```bash
cd deploy/ecs/terraform

# Initialize Terraform
terraform init

# Create terraform.tfvars
cat > terraform.tfvars <<EOF
project_name     = "{{ project_slug }}"
environment      = "production"
aws_region       = "us-east-1"
# ECR repository is automatically created by Terraform
# container_image is only needed if using external image
django_secret_key = "$(python -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())')"
django_debug      = false
allowed_hosts    = "{{ project_slug }}.example.com"
EOF
```

#### 3. Deploy Infrastructure

```bash
# Plan deployment
terraform plan

# Apply deployment
terraform apply

# Get ALB URL
terraform output alb_url
```

## Deployment Script Features

The `deploy.sh` script provides comprehensive deployment automation:

### Interactive Menu

```bash
./deploy/ecs/deploy.sh
```

Options:
1. **Full deployment** - Complete end-to-end deployment
2. **Build and push** - Docker image management only
3. **Deploy infrastructure** - Terraform deployment only
4. **Update ECS service** - Rolling update of running service
5. **Run migrations** - Database migration management
6. **Show deployment info** - Display current deployment status
7. **Generate tfvars** - Create Terraform variables file
8. **Rollback** - Revert to previous task definition
9. **Destroy** - Remove all infrastructure

### Command Line Options

```bash
./deploy/ecs/deploy.sh [options]

Options:
  -e, --environment ENV    Environment (dev/staging/production)
  -r, --region REGION      AWS region
  -t, --image-tag TAG      Docker image tag
  -y, --auto               Auto approve all prompts
  -h, --help               Show help message
```

### Environment-Specific Deployments

```bash
# Development
./deploy/ecs/deploy.sh --environment dev --region us-east-1

# Staging
./deploy/ecs/deploy.sh --environment staging --region us-west-2

# Production
./deploy/ecs/deploy.sh --environment production --region eu-west-1
```

## Architecture

```
Internet
   |
   v
Application Load Balancer (ALB)
   |
   v
ECS Service (Fargate)
   |
   +-- Task 1 (Container)
   +-- Task 2 (Container)
   +-- Task N (Container)
   |
   v
RDS PostgreSQL / Aurora Serverless
   |
   v
S3 (Static/Media Files)
```

## Configuration

### Environment Variables

Set these in AWS Secrets Manager or Systems Manager Parameter Store:

```bash
DJANGO_SECRET_KEY=<your-secret-key>
DATABASE_URL=postgresql://...
ALLOWED_HOSTS={{ project_slug }}.example.com
DEBUG=False
{% if cache == 'redis' -%}
REDIS_URL=redis://...
{% endif -%}
{% if background_tasks in ['celery', 'both'] -%}
CELERY_BROKER_URL=redis://...
{% endif -%}
{% if use_sentry -%}
SENTRY_DSN=<your-sentry-dsn>
{% endif -%}
AWS_STORAGE_BUCKET_NAME={{ project_slug }}-media
AWS_ACCESS_KEY_ID=<from-iam>
AWS_SECRET_ACCESS_KEY=<from-iam>
```

### Task Definition

The ECS task definition includes:

- **CPU**: 256-1024 (0.25-1 vCPU)
- **Memory**: 512-2048 MB
- **Port Mappings**: 8000 (Gunicorn)
- **Health Check**: `/health/` endpoint
- **Logging**: CloudWatch Logs

### Auto Scaling

Auto-scaling configuration:

- **Min Tasks**: 2
- **Max Tasks**: 10
- **Target CPU**: 70%
- **Target Memory**: 80%
- **Scale-in Cooldown**: 300s
- **Scale-out Cooldown**: 60s

## Database Options

### RDS PostgreSQL

```hcl
# Deploy with RDS
terraform apply -var="use_aurora=false"
```

### Aurora Serverless v2

```hcl
# Deploy with Aurora Serverless
terraform apply -var="use_aurora=true"
```

Benefits of Aurora Serverless:
- Automatically scales based on load
- Pay per second
- Pause when inactive (dev/staging)

## Static & Media Files

Configure S3 for static and media files:

```python
# settings/prod.py
AWS_STORAGE_BUCKET_NAME = env("AWS_STORAGE_BUCKET_NAME")
AWS_S3_REGION_NAME = env("AWS_REGION", default="us-east-1")
AWS_S3_CUSTOM_DOMAIN = f"{AWS_STORAGE_BUCKET_NAME}.s3.amazonaws.com"

# Static files
STATICFILES_STORAGE = "storages.backends.s3boto3.S3StaticStorage"

# Media files
DEFAULT_FILE_STORAGE = "storages.backends.s3boto3.S3Boto3Storage"
```

## Migrations

### One-Time Migrations

Run migrations as a one-off task:

```bash
aws ecs run-task \
  --cluster {{ project_slug }}-cluster \
  --task-definition {{ project_slug }}-migrate \
  --launch-type FARGATE \
  --network-configuration "awsvpcConfiguration={subnets=[subnet-xxx],securityGroups=[sg-xxx],assignPublicIp=ENABLED}"
```

### Automated Migrations

Use ECS Exec or create a migration task that runs before deployment.

## Monitoring

### CloudWatch Metrics

Key metrics to monitor:

- CPU Utilization
- Memory Utilization
- Request Count
- Target Response Time
- Unhealthy Host Count

### CloudWatch Alarms

Set up alarms for:

- High CPU (> 80%)
- High Memory (> 85%)
- Failed Health Checks
- 5xx Error Rate

### Logs

View logs:

```bash
# Stream logs
aws logs tail /ecs/{{ project_slug }} --follow

# Filter for errors
aws logs filter-log-events \
  --log-group-name /ecs/{{ project_slug }} \
  --filter-pattern "ERROR"
```

## CI/CD Integration

### GitHub Actions

```yaml
name: Deploy to ECS

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: {% raw %}${{ secrets.AWS_ACCESS_KEY_ID }}{% endraw %}
          aws-secret-access-key: {% raw %}${{ secrets.AWS_SECRET_ACCESS_KEY }}{% endraw %}
          aws-region: us-east-1

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build and push image
        env:
          ECR_REGISTRY: {% raw %}${{ steps.login-ecr.outputs.registry }}{% endraw %}
          IMAGE_TAG: {% raw %}${{ github.sha }}{% endraw %}
        run: |
          docker build -t $ECR_REGISTRY/{{ project_slug }}:$IMAGE_TAG .
          docker push $ECR_REGISTRY/{{ project_slug }}:$IMAGE_TAG

      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster {{ project_slug }}-cluster \
            --service {{ project_slug }}-service \
            --force-new-deployment
```

## Cost Optimization

Tips for reducing costs:

1. **Right-size tasks**: Start with smaller CPU/memory
2. **Use Spot**: Consider Fargate Spot for non-critical workloads
3. **Aurora Serverless**: Auto-pause in dev/staging
4. **CloudWatch retention**: Set log retention to 7-30 days
5. **S3 lifecycle**: Move old media to Glacier
6. **Reserved capacity**: For predictable workloads

## Troubleshooting

### Task Won't Start

Check:
- ECR image exists and is accessible
- Security groups allow traffic
- Subnets have route to internet (for pulling images)
- IAM role has correct permissions

### Health Check Failing

- Ensure `/health/` endpoint is accessible
- Check security group rules
- Verify container is listening on port 8000
- Check CloudWatch logs for errors

### High Costs

- Review CloudWatch metrics for over-provisioning
- Consider Aurora Serverless pause
- Enable S3 lifecycle policies
- Use Fargate Spot for dev/staging

## Cleanup

To destroy all resources:

```bash
cd deploy/ecs/terraform
terraform destroy
```

## Resources

- [AWS ECS Best Practices](https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/)
- [Fargate Pricing](https://aws.amazon.com/fargate/pricing/)
- [Django on ECS Guide](https://testdriven.io/blog/deploying-django-to-ecs-with-terraform/)
